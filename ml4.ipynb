{
 "cells": [
  {
   "cell_type": "raw",
   "id": "9adddc75-a04f-42b5-88e1-f1ac47684386",
   "metadata": {},
   "source": [
    "Q1. What is Min-Max scaling, and how is it used in data preprocessing? Provide an example to illustrate its application.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "96879d47-75d9-44ce-8429-64c9f88e1a10",
   "metadata": {},
   "source": [
    "Ans:-\n",
    "Min Max Scaling-\n",
    "In min-max you will subtract the minimum value in the dataset with all the values and then divide this by the range of the dataset(maximum-minimum). In this case, your dataset will lie between 0 and 1 in all cases whereas in the previous case, it was between -1 and +1.\n",
    "\n",
    "\n",
    "MinMaxScaler is useful when the data has a bounded range or when the distribution is not Gaussian. For example, in image processing, pixel values are typically in the range of 0-255. Scaling these values using MinMaxScaler ensures that the values are within a fixed range and contributes equally to the analysis."
   ]
  },
  {
   "cell_type": "raw",
   "id": "66fe2434-650a-4e31-bc2c-a931b1ea404d",
   "metadata": {},
   "source": [
    "Q2. What is the Unit Vector technique in feature scaling, and how does it differ from Min-Max scaling? Provide an example to illustrate its application.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4a27b1e4-e10d-4f1e-8f60-7d6b2b3e8ba3",
   "metadata": {},
   "source": [
    "Ans:-\n",
    "Unit Vector Scaling technique is done considering the whole feature vector to be of unit length,Unit vector scaling means dividing each component by the Euclidean length of the vector (L2 Norm),Unit Vector technique produces values of range [0,1].\n",
    "\n",
    "Example, if we have weight of a person in a dataset with values in the range 15kg to 100kg, then feature scaling transforms all the values to the range 0 to 1 where 0 represents lowest weight and 1 represents highest weight instead of representing the weights in kgs."
   ]
  },
  {
   "cell_type": "raw",
   "id": "ed061200-e1b2-46d8-b396-7d6b7b509fd9",
   "metadata": {},
   "source": [
    "Q3. What is PCA (Principle Component Analysis), and how is it used in dimensionality reduction? Provide an example to illustrate its application.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fd74a106-7e26-4f37-a48a-2916e331453d",
   "metadata": {},
   "source": [
    "Ans:-\n",
    "Reducing the number of variables in a data collection while retaining as much information as feasible is the main goal of PCA. PCA can be mainly used for Dimensionality Reduction and also for important feature selection.PCA helps us to identify patterns in data based on the correlation between features. In a nutshell, PCA aims to find the directions of maximum variance in high-dimensional data and projects it onto a new subspace with equal or fewer dimensions than the original one.\n",
    "\n",
    "Example-\n",
    "Principal Component Analysis (PCA) is a mathematical technique to reduce the dimensionality of data. It works on the principal of factoring matrices to extract the principal pattern of a linear system."
   ]
  },
  {
   "cell_type": "raw",
   "id": "9dd956ca-f9f9-491c-9b30-af1c477522cb",
   "metadata": {},
   "source": [
    "Q4. What is the relationship between PCA and Feature Extraction, and how can PCA be used for Feature Extraction? Provide an example to illustrate this concept.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f3acdb14-13b4-46ae-ae9a-ed0cb09c3371",
   "metadata": {},
   "source": [
    "Ans:-\n",
    "Principal component analysis (PCA) is an unsupervised linear transformation technique which is primarily used for feature extraction and dimensionality reduction.\n",
    "In many datasets we find that number of features are very large and if we want to train the model it take more computational cost. To decrease the number of features we can use Principal component analysis (PCA). PCA decrease the number of features by selecting dimension of features which have most of the variance.\n",
    "\n",
    "Principal component analysis, or PCA, is a statistical procedure that allows you to summarize the information content in large data tables by means of a smaller set of “summary indices” that can be more easily visualized and analyzed.\n",
    "\n",
    "Some real-world applications of PCA are image processing, movie recommendation system, optimizing the power allocation in various communication channels. It is a feature extraction technique, so it contains the important variables and drops the least important variable."
   ]
  },
  {
   "cell_type": "raw",
   "id": "abe1ac47-1801-4fc9-abf4-aa16b6f51ba8",
   "metadata": {},
   "source": [
    "Q5. You are working on a project to build a recommendation system for a food delivery service. The dataset contains features such as price, rating, and delivery time. Explain how you would use Min-Max scaling to preprocess the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3884e9c7-6204-4f56-9e1b-42ec4052a44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data={'price':[150,200,145,165,198,365],\n",
    "     'rating':[5,4,3,1,5,2],\n",
    "     'delivery_time':['10:00','11:00','10:30','11:30','10:45','11:15']}\n",
    "df=pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff6a6428-2250-4cc5-b5bd-6ec500109e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02272727, 1.        ],\n",
       "       [0.25      , 0.75      ],\n",
       "       [0.        , 0.5       ],\n",
       "       [0.09090909, 0.        ],\n",
       "       [0.24090909, 1.        ],\n",
       "       [1.        , 0.25      ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()\n",
    "scaler.fit(df[[\"price\",\"rating\"]])\n",
    "scaler.transform(df[[\"price\",\"rating\"]])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "75477110-e453-412c-8042-a4823608044d",
   "metadata": {},
   "source": [
    "Q6. You are working on a project to build a model to predict stock prices. The dataset contains many features, such as company financial data and market trends. Explain how you would use PCA to reduce the dimensionality of the dataset.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f5b8b683-4fb7-4e43-8ca7-7d0cd467cf36",
   "metadata": {},
   "source": [
    "Ans:-\n",
    "Steps:\n",
    "1.Standardize the range of continuous initial variables\n",
    "2.Compute the covariance matrix to identify correlations\n",
    "3.Compute the eigenvectors and eigenvalues of the covariance matrix to identify the principal components\n",
    "4.Create a feature vector to decide which principal components to keep\n",
    "5.Recast the data along the principal components axes"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2ae8f1e8-8f37-4261-b7ad-ed70f6ee2697",
   "metadata": {},
   "source": [
    "Q7. For a dataset containing the following values: [1, 5, 10, 15, 20], perform Min-Max scaling to transform the values to a range of -1 to 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c886f55a-aaf5-46b1-a442-f78f33b0b405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "data=[[1,5,10,15,20]]\n",
    "scaler=MinMaxScaler()\n",
    "scaler.fit(data)\n",
    "scaler.transform(data)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "53fb38b1-5683-4219-8105-88020499ca48",
   "metadata": {},
   "source": [
    "Q8. For a dataset containing the following features: [height, weight, age, gender, blood pressure], perform Feature Extraction using PCA. How many principal components would you choose to retain, and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a6a0d0b-3001-486e-8ba4-e3a1286662ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data={'height':[120,130,140,125,130,145,124],\n",
    "     'weight':[50,60,55,65,45,60,46],\n",
    "     'age':[25,30,26,35,23,32,26],\n",
    "     'gender':['male','female','female','male','male','female','male'],\n",
    "     'blood_pressure':[120,125,130,125,130,142,110]}\n",
    "df=pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfee1804-7b81-4a87-b53c-76eda69b2edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>blood_pressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "      <td>male</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>130</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>female</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>140</td>\n",
       "      <td>55</td>\n",
       "      <td>26</td>\n",
       "      <td>female</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>125</td>\n",
       "      <td>65</td>\n",
       "      <td>35</td>\n",
       "      <td>male</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>130</td>\n",
       "      <td>45</td>\n",
       "      <td>23</td>\n",
       "      <td>male</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>145</td>\n",
       "      <td>60</td>\n",
       "      <td>32</td>\n",
       "      <td>female</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>124</td>\n",
       "      <td>46</td>\n",
       "      <td>26</td>\n",
       "      <td>male</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   height  weight  age  gender  blood_pressure\n",
       "0     120      50   25    male             120\n",
       "1     130      60   30  female             125\n",
       "2     140      55   26  female             130\n",
       "3     125      65   35    male             125\n",
       "4     130      45   23    male             130\n",
       "5     145      60   32  female             142\n",
       "6     124      46   26    male             110"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cab19deb-ae82-4c2c-a800-35ea319521dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-11.45709547,   2.95763181,  -1.11007896],\n",
       "       [  3.44630977,   4.65717551,  -1.1180303 ],\n",
       "       [  6.75778037,  -6.73215628,  -1.68130986],\n",
       "       [  4.159325  ,  13.12240357,   0.56468273],\n",
       "       [ -7.56327633,  -7.64625609,   0.07133288],\n",
       "       [ 15.22859295,  -4.50785762,   1.36792441],\n",
       "       [-10.57163628,  -1.85094091,   1.9054791 ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca=PCA()\n",
    "pca.fit(df[[\"height\",\"weight\",\"age\"]])\n",
    "pca.transform(df[[\"height\",\"weight\",\"age\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd28d16-010e-414a-9635-be8cc93beda8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
